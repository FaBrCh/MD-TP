{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 3: Trabalho Prático de Mineração de Dados - Conclusão e Análise Comparativa\n",
    "\n",
    "**Alunos:** Gilmar Junio, Fabrício Chaves\n",
    "\n",
    "Este notebook documenta a Fase 3 do Trabalho Prático de Mineração de Dados. O objetivo é consolidar as análises de padrões frequentes em dados de e-commerce, realizar análises segmentadas propostas, refinar a avaliação e apresentar uma análise comparativa do trabalho desenvolvido com auxílio do LLM (Fase 2) versus as conclusões e refinamentos do grupo (Fase 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding (Entendimento do Negócio)\n",
    "\n",
    "(Esta seção pode ser copiada da Fase 2, pois o contexto de negócio permanece o mesmo)\n",
    "\n",
    "**Contexto:** Análise de transações de vendas de um e-commerce do Reino Unido.\n",
    "\n",
    "**Relevância:**\n",
    "*   Compreender o comportamento de compra dos clientes.\n",
    "*   Melhorar estratégias de *cross-selling* e *up-selling*.\n",
    "*   Otimizar estoque e promoções com base em produtos frequentemente comprados juntos.\n",
    "\n",
    "**Objetivo Principal:** Identificar itens frequentemente comprados juntos para embasar recomendações de produtos e estratégias de marketing.\n",
    "\n",
    "**Objetivos Específicos:**\n",
    "*   Encontrar *itemsets* frequentes (conjuntos de produtos que aparecem juntos em transações).\n",
    "*   Extrair regras de associação (ex.: \"Se compra X, então compra Y\").\n",
    "*   Analisar possíveis diferenças nos padrões por país ou tipo de cliente (se viável).\n",
    "\n",
    "**Critérios de Sucesso (Negócio):**\n",
    "*   Identificar regras de associação acionáveis.\n",
    "*   Gerar visualizações claras dos padrões encontrados.\n",
    "*   Propor ações práticas (ex.: promoções combinadas, layout de site).\n",
    "\n",
    "**Objetivos da Mineração de Dados:**\n",
    "*   Aplicar algoritmos como Apriori ou FP-Growth para encontrar *itemsets* frequentes.\n",
    "*   Gerar regras de associação com métricas de suporte, confiança e *lift*.\n",
    "*   Filtrar regras para focar nas mais relevantes (ex: `lift > 1`).\n",
    "\n",
    "**Critérios de Sucesso (Mineração):**\n",
    "*   Gerar regras com `min_support` e `min_confidence` definidos (ex: 0.01 e 0.5, conforme proposta).\n",
    "*   Avaliar a qualidade das regras encontradas usando as métricas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding & Data Preparation (Entendimento e Preparação dos Dados)\n",
    "\n",
    "Nesta etapa, carregamos os dados originais e aplicamos os passos de limpeza e transformação consolidados da Fase 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "# Configurações de visualização (opcional)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original carregado com 536350 linhas e 8 colunas.\n",
      "Dataset após limpeza: 522601 linhas e 8 colunas.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 522601 entries, 0 to 536324\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   TransactionNo  522601 non-null  object        \n",
      " 1   Date           522601 non-null  datetime64[ns]\n",
      " 2   ProductNo      522601 non-null  object        \n",
      " 3   ProductName    522601 non-null  object        \n",
      " 4   Price          522601 non-null  float64       \n",
      " 5   Quantity       522601 non-null  int64         \n",
      " 6   CustomerNo     522601 non-null  int32         \n",
      " 7   Country        522601 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int32(1), int64(1), object(4)\n",
      "memory usage: 33.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Carregar o dataset original\n",
    "file_path = 'Sales Transaction v.4a.csv' # Ajuste se o nome/caminho for diferente\n",
    "try:\n",
    "    df_original = pd.read_csv(file_path)\n",
    "except UnicodeDecodeError:\n",
    "    df_original = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "print(f'Dataset original carregado com {df_original.shape[0]} linhas e {df_original.shape[1]} colunas.')\n",
    "\n",
    "# Aplicar limpeza consolidada (baseada nas decisões da Fase 2)\n",
    "df_cleaned = df_original.copy()\n",
    "\n",
    "# 1. Remover linhas com CustomerNo nulo\n",
    "df_cleaned.dropna(subset=['CustomerNo'], inplace=True)\n",
    "\n",
    "# 2. Converter Date para datetime\n",
    "try:\n",
    "    df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'])\n",
    "except ValueError:\n",
    "    df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# 3. Remover linhas com Quantity <= 0\n",
    "df_cleaned = df_cleaned[df_cleaned['Quantity'] > 0]\n",
    "\n",
    "# 4. Remover linhas com Price <= 0 (verificação de segurança, embora na Fase 2 não removeu nenhuma)\n",
    "df_cleaned = df_cleaned[df_cleaned['Price'] > 0]\n",
    "\n",
    "# 5. Remover transações canceladas (TransactionNo começando com 'C')\n",
    "df_cleaned['TransactionNo'] = df_cleaned['TransactionNo'].astype(str)\n",
    "df_cleaned = df_cleaned[~df_cleaned['TransactionNo'].str.startswith('C')]\n",
    "\n",
    "# 6. Converter CustomerNo para inteiro\n",
    "df_cleaned['CustomerNo'] = df_cleaned['CustomerNo'].astype(int)\n",
    "\n",
    "# 7. Remover duplicatas\n",
    "df_cleaned.drop_duplicates(inplace=True)\n",
    "\n",
    "# 8. Limpar espaços extras em ProductName\n",
    "df_cleaned['ProductName'] = df_cleaned['ProductName'].str.strip()\n",
    "\n",
    "print(f'Dataset após limpeza: {df_cleaned.shape[0]} linhas e {df_cleaned.shape[1]} colunas.')\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Transformação para Formato Transacional (Dataset Completo)\n",
    "\n",
    "Agrupamos os itens por transação para o dataset limpo completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de transações únicas (dataset completo): 19789\n",
      "\n",
      "Exemplo das primeiras 2 listas de transações (dataset completo):\n",
      "Transação 1: ['Cream Hanging Heart T-Light Holder', 'White Moroccan Metal Lantern', 'Cream Cupid Hearts Coat Hanger', 'Knitted Union Flag Hot Water Bottle', 'Red Woolly Hottie White Heart', 'Set 7 Babushka Nesting Boxes', 'Glass Star Frosted T-Light Holder']\n",
      "Transação 2: ['Hand Warmer Union Jack', 'Hand Warmer Red Retrospot']\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por TransactionNo e listar os ProductName para o dataset completo\n",
    "transactions_series_all = df_cleaned.groupby('TransactionNo')['ProductName'].apply(list)\n",
    "transactions_list_all = transactions_series_all.tolist()\n",
    "\n",
    "print(f'Número de transações únicas (dataset completo): {len(transactions_list_all)}')\n",
    "if len(transactions_list_all) > 1:\n",
    "    print('\\nExemplo das primeiras 2 listas de transações (dataset completo):')\n",
    "    for i in range(min(2, len(transactions_list_all))):\n",
    "        print(f\"Transação {i+1}: {transactions_list_all[i]}\")\n",
    "else:\n",
    "    print(\"Não há transações suficientes para mostrar exemplos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling (Modelagem - Análise Geral)\n",
    "\n",
    "Aplicamos o algoritmo FP-Growth ao dataset completo limpo para encontrar padrões frequentes e regras de associação. Estes resultados serão predominantemente influenciados pelas transações do Reino Unido, dada a sua proporção nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões do DataFrame codificado (completo): (19789, 3753)\n",
      "\n",
      "Encontrados 2029 itemsets frequentes (dataset completo) com suporte >= 0.01\n",
      "\n",
      "Top 10 itemsets frequentes (dataset completo):\n",
      "      support                              itemsets\n",
      "0    0.114660  (Cream Hanging Heart T-Light Holder)\n",
      "96   0.105715             (Jumbo Bag Red Retrospot)\n",
      "313  0.100510            (Regency Cakestand 3 Tier)\n",
      "615  0.085249                       (Party Bunting)\n",
      "43   0.079185             (Lunch Bag Red Retrospot)\n",
      "8    0.073627       (Assorted Colour Bird Ornament)\n",
      "109  0.070342                      (Popcorn Holder)\n",
      "647  0.069988    (Set Of 3 Cake Tins Pantry Design)\n",
      "44   0.066805     (Pack Of 72 Retrospot Cake Cases)\n",
      "178  0.064986               (Lunch Bag Suki Design)\n",
      "\n",
      "Encontradas 963 regras de associação (dataset completo) com confiança >= 0.5 e lift > 1\n",
      "\n",
      "Top 10 regras de associação (dataset completo, ordenadas por lift e confiança):\n",
      "                                     antecedents  \\\n",
      "859  (Herb Marker Rosemary, Herb Marker Parsley)   \n",
      "864                          (Herb Marker Thyme)   \n",
      "861     (Herb Marker Parsley, Herb Marker Thyme)   \n",
      "862                       (Herb Marker Rosemary)   \n",
      "910       (Herb Marker Basil, Herb Marker Thyme)   \n",
      "913                       (Herb Marker Rosemary)   \n",
      "909    (Herb Marker Basil, Herb Marker Rosemary)   \n",
      "914                          (Herb Marker Thyme)   \n",
      "619                          (Herb Marker Thyme)   \n",
      "618                       (Herb Marker Rosemary)   \n",
      "\n",
      "                                     consequents   support  confidence  \\\n",
      "859                          (Herb Marker Thyme)  0.010258    0.944186   \n",
      "864  (Herb Marker Rosemary, Herb Marker Parsley)  0.010258    0.856540   \n",
      "861                       (Herb Marker Rosemary)  0.010258    0.953052   \n",
      "862     (Herb Marker Parsley, Herb Marker Thyme)  0.010258    0.845833   \n",
      "910                       (Herb Marker Rosemary)  0.010107    0.952381   \n",
      "913       (Herb Marker Basil, Herb Marker Thyme)  0.010107    0.833333   \n",
      "909                          (Herb Marker Thyme)  0.010107    0.934579   \n",
      "914    (Herb Marker Basil, Herb Marker Rosemary)  0.010107    0.843882   \n",
      "619                       (Herb Marker Rosemary)  0.011168    0.932489   \n",
      "618                          (Herb Marker Thyme)  0.011168    0.920833   \n",
      "\n",
      "          lift  \n",
      "859  78.837543  \n",
      "864  78.837543  \n",
      "861  78.583079  \n",
      "862  78.583079  \n",
      "910  78.527778  \n",
      "913  78.527778  \n",
      "909  78.035411  \n",
      "914  78.035411  \n",
      "619  76.887641  \n",
      "618  76.887641  \n"
     ]
    }
   ],
   "source": [
    "# Codificar os dados completos (One-Hot Encoding)\n",
    "te_all = TransactionEncoder()\n",
    "te_ary_all = te_all.fit(transactions_list_all).transform(transactions_list_all)\n",
    "df_encoded_all = pd.DataFrame(te_ary_all, columns=te_all.columns_)\n",
    "\n",
    "print(f\"Dimensões do DataFrame codificado (completo): {df_encoded_all.shape}\")\n",
    "\n",
    "# Aplicar o FP-Growth\n",
    "min_support_threshold_all = 0.01\n",
    "frequent_itemsets_all = fpgrowth(df_encoded_all, min_support=min_support_threshold_all, use_colnames=True)\n",
    "frequent_itemsets_all = frequent_itemsets_all.sort_values(by='support', ascending=False)\n",
    "\n",
    "print(f\"\\nEncontrados {len(frequent_itemsets_all)} itemsets frequentes (dataset completo) com suporte >= {min_support_threshold_all}\")\n",
    "print(\"\\nTop 10 itemsets frequentes (dataset completo):\")\n",
    "print(frequent_itemsets_all.head(10))\n",
    "\n",
    "# Gerar Regras de Associação\n",
    "min_confidence_threshold_all = 0.5\n",
    "rules_all = association_rules(frequent_itemsets_all, metric=\"confidence\", min_threshold=min_confidence_threshold_all)\n",
    "rules_all = rules_all[rules_all['lift'] > 1]\n",
    "rules_all = rules_all.sort_values(by=['lift', 'confidence'], ascending=[False, False])\n",
    "\n",
    "print(f\"\\nEncontradas {len(rules_all)} regras de associação (dataset completo) com confiança >= {min_confidence_threshold_all} e lift > 1\")\n",
    "print(\"\\nTop 10 regras de associação (dataset completo, ordenadas por lift e confiança):\")\n",
    "print(rules_all.head(10)[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Modeling (Modelagem - Análise Segmentada por País)\n",
    "\n",
    "Conforme o objetivo específico da proposta, analisamos se existem padrões de compra diferentes em outros países. Dada a distribuição dos dados, focaremos na Alemanha e, se viável, na França.\n",
    "\n",
    "### 4.1. Análise para a Alemanha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros para a Alemanha: 10221\n",
      "Número de transações únicas (Alemanha): 453\n",
      "Dimensões do DataFrame codificado (Alemanha): (453, 2069)\n",
      "Muitos itemsets com suporte 0.01. Tentando com suporte maior...\n",
      "\n",
      "Encontrados 260 itemsets frequentes (Alemanha) com suporte >= 0.03\n",
      "\n",
      "Top 5 itemsets frequentes (Alemanha):\n",
      "     support                              itemsets\n",
      "19  0.240618  (Round Snack Boxes Set Of4 Woodland)\n",
      "20  0.154525   (Round Snack Boxes Set Of 4 Fruits)\n",
      "21  0.141280            (Regency Cakestand 3 Tier)\n",
      "40  0.136865    (Plasters In Tin Woodland Animals)\n",
      "22  0.132450              (Woodland Charlotte Bag)\n",
      "\n",
      "Encontradas 185 regras de associação (Alemanha) com confiança >= 0.2 e lift > 1\n",
      "\n",
      "Top 5 regras de associação (Alemanha, ordenadas por lift e confiança):\n",
      "                        antecedents                     consequents   support  \\\n",
      "105        (Spaceboy Childrens Cup)       (Spaceboy Childrens Bowl)  0.035320   \n",
      "106       (Spaceboy Childrens Bowl)        (Spaceboy Childrens Cup)  0.035320   \n",
      "78     (Childrens Cutlery Spaceboy)  (Childrens Cutlery Dolly Girl)  0.037528   \n",
      "77   (Childrens Cutlery Dolly Girl)    (Childrens Cutlery Spaceboy)  0.037528   \n",
      "134      (Coffee Mug Apples Design)       (Coffee Mug Pears Design)  0.033113   \n",
      "\n",
      "     confidence       lift  \n",
      "105    0.888889  22.370370  \n",
      "106    0.888889  22.370370  \n",
      "78     0.809524  16.668831  \n",
      "77     0.772727  16.668831  \n",
      "134    0.576923  15.373303  \n"
     ]
    }
   ],
   "source": [
    "# Filtrar dados para a Alemanha\n",
    "df_germany = df_cleaned[df_cleaned['Country'] == 'Germany']\n",
    "print(f\"Número de registros para a Alemanha: {len(df_germany)}\")\n",
    "\n",
    "# Transformar para formato transacional (Alemanha)\n",
    "transactions_series_germany = df_germany.groupby('TransactionNo')['ProductName'].apply(list)\n",
    "transactions_list_germany = transactions_series_germany.tolist()\n",
    "print(f\"Número de transações únicas (Alemanha): {len(transactions_list_germany)}\")\n",
    "\n",
    "if len(transactions_list_germany) > 10: # Checar se há um número mínimo razoável de transações\n",
    "    te_germany = TransactionEncoder()\n",
    "    te_ary_germany = te_germany.fit(transactions_list_germany).transform(transactions_list_germany)\n",
    "    df_encoded_germany = pd.DataFrame(te_ary_germany, columns=te_germany.columns_)\n",
    "    print(f\"Dimensões do DataFrame codificado (Alemanha): {df_encoded_germany.shape}\")\n",
    "\n",
    "    # Aplicar FP-Growth para Alemanha\n",
    "    # Pode ser necessário um min_support menor devido ao volume de dados\n",
    "    min_support_germany = 0.01 # Comece com 0.01, ajuste se necessário (ex: 0.02, 0.03 ou até mais se gerar muitas regras)\n",
    "    \n",
    "    # Tentar com min_support inicial, se gerar poucas/muitas regras, ajustar\n",
    "    frequent_itemsets_germany = fpgrowth(df_encoded_germany, min_support=min_support_germany, use_colnames=True)\n",
    "    \n",
    "    # Ajuste dinâmico do min_support se poucas regras forem encontradas\n",
    "    # Esta é uma heurística simples, pode precisar de mais refinamento\n",
    "    if len(frequent_itemsets_germany) < 10 and len(frequent_itemsets_germany) > 0 : # Se muito poucas, tentar reduzir o suporte\n",
    "        print(f\"Poucos itemsets com suporte {min_support_germany}. Tentando com suporte menor...\")\n",
    "        min_support_germany = 0.005 \n",
    "        frequent_itemsets_germany = fpgrowth(df_encoded_germany, min_support=min_support_germany, use_colnames=True)\n",
    "    elif len(frequent_itemsets_germany) > 5000: # Se muitas, tentar aumentar o suporte\n",
    "         print(f\"Muitos itemsets com suporte {min_support_germany}. Tentando com suporte maior...\")\n",
    "         min_support_germany = 0.03\n",
    "         frequent_itemsets_germany = fpgrowth(df_encoded_germany, min_support=min_support_germany, use_colnames=True)\n",
    "\n",
    "\n",
    "    if not frequent_itemsets_germany.empty:\n",
    "        frequent_itemsets_germany = frequent_itemsets_germany.sort_values(by='support', ascending=False)\n",
    "        print(f\"\\nEncontrados {len(frequent_itemsets_germany)} itemsets frequentes (Alemanha) com suporte >= {min_support_germany}\")\n",
    "        print(\"\\nTop 5 itemsets frequentes (Alemanha):\")\n",
    "        print(frequent_itemsets_germany.head(5))\n",
    "\n",
    "        # Gerar Regras de Associação para Alemanha\n",
    "        min_confidence_germany = 0.2 # Pode ser necessário ajustar a confiança também, talvez um pouco menor\n",
    "        rules_germany = association_rules(frequent_itemsets_germany, metric=\"confidence\", min_threshold=min_confidence_germany)\n",
    "        \n",
    "        if not rules_germany.empty:\n",
    "            rules_germany = rules_germany[rules_germany['lift'] > 1]\n",
    "            rules_germany = rules_germany.sort_values(by=['lift', 'confidence'], ascending=[False, False])\n",
    "            print(f\"\\nEncontradas {len(rules_germany)} regras de associação (Alemanha) com confiança >= {min_confidence_germany} e lift > 1\")\n",
    "            print(\"\\nTop 5 regras de associação (Alemanha, ordenadas por lift e confiança):\")\n",
    "            print(rules_germany.head(5)[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "        else:\n",
    "            print(\"Nenhuma regra de associação encontrada para a Alemanha com os critérios atuais.\")\n",
    "    else:\n",
    "        print(f\"Nenhum itemset frequente encontrado para a Alemanha com suporte >= {min_support_germany}.\")\n",
    "else:\n",
    "    print(\"Número de transações para a Alemanha é muito baixo para uma análise significativa de padrões frequentes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Análise para a França"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros para a França: 10377\n",
      "Número de transações únicas (França): 404\n",
      "Dimensões do DataFrame codificado (França): (404, 2027)\n",
      "\n",
      "Encontrados 1370 itemsets frequentes (França) com suporte >= 0.02\n",
      "\n",
      "Top 5 itemsets frequentes (França):\n",
      "      support                            itemsets\n",
      "256  0.193069                (Rabbit Night Light)\n",
      "0    0.190594     (Red Toadstool Led Night Light)\n",
      "146  0.170792     (Plasters In Tin Circus Parade)\n",
      "29   0.168317  (Plasters In Tin Woodland Animals)\n",
      "18   0.163366           (Lunch Bag Red Retrospot)\n",
      "\n",
      "Encontradas 3737 regras de associação (França) com confiança >= 0.2 e lift > 1\n",
      "\n",
      "Top 5 regras de associação (França, ordenadas por lift e confiança):\n",
      "                                              antecedents  \\\n",
      "2887                           (Set/6 Collage Paper Cups)   \n",
      "2888                         (Set/6 Collage Paper Plates)   \n",
      "2714                 (Small Dolly Mix Design Orange Bowl)   \n",
      "2715                       (Small Marshmallows Pink Bowl)   \n",
      "1937  (Spaceboy Childrens Cup, Dolly Girl Childrens Bowl)   \n",
      "\n",
      "                                              consequents   support  \\\n",
      "2887                         (Set/6 Collage Paper Plates)  0.022277   \n",
      "2888                           (Set/6 Collage Paper Cups)  0.022277   \n",
      "2714                       (Small Marshmallows Pink Bowl)  0.022277   \n",
      "2715                 (Small Dolly Mix Design Orange Bowl)  0.022277   \n",
      "1937  (Dolly Girl Childrens Cup, Spaceboy Childrens Bowl)  0.027228   \n",
      "\n",
      "      confidence       lift  \n",
      "2887         1.0  44.888889  \n",
      "2888         1.0  44.888889  \n",
      "2714         0.9  36.360000  \n",
      "2715         0.9  36.360000  \n",
      "1937         1.0  31.076923  \n"
     ]
    }
   ],
   "source": [
    "# Filtrar dados para a França\n",
    "df_france = df_cleaned[df_cleaned['Country'] == 'France']\n",
    "print(f\"Número de registros para a França: {len(df_france)}\")\n",
    "\n",
    "# Transformar para formato transacional (França)\n",
    "transactions_series_france = df_france.groupby('TransactionNo')['ProductName'].apply(list)\n",
    "transactions_list_france = transactions_series_france.tolist()\n",
    "print(f\"Número de transações únicas (França): {len(transactions_list_france)}\")\n",
    "\n",
    "if len(transactions_list_france) > 10: # Checar se há um número mínimo razoável de transações\n",
    "    te_france = TransactionEncoder()\n",
    "    te_ary_france = te_france.fit(transactions_list_france).transform(transactions_list_france)\n",
    "    df_encoded_france = pd.DataFrame(te_ary_france, columns=te_france.columns_)\n",
    "    print(f\"Dimensões do DataFrame codificado (França): {df_encoded_france.shape}\")\n",
    "\n",
    "    # Aplicar FP-Growth para França\n",
    "    min_support_france = 0.02 # Começar com um valor um pouco maior que o da Alemanha, ajustar se necessário\n",
    "    \n",
    "    frequent_itemsets_france = fpgrowth(df_encoded_france, min_support=min_support_france, use_colnames=True)\n",
    "    \n",
    "    # Ajuste dinâmico do min_support\n",
    "    if len(frequent_itemsets_france) < 5 and len(frequent_itemsets_france) > 0:\n",
    "        print(f\"Poucos itemsets com suporte {min_support_france}. Tentando com suporte menor...\")\n",
    "        min_support_france = 0.01\n",
    "        frequent_itemsets_france = fpgrowth(df_encoded_france, min_support=min_support_france, use_colnames=True)\n",
    "    elif len(frequent_itemsets_france) > 3000:\n",
    "         print(f\"Muitos itemsets com suporte {min_support_france}. Tentando com suporte maior...\")\n",
    "         min_support_france = 0.04\n",
    "         frequent_itemsets_france = fpgrowth(df_encoded_france, min_support=min_support_france, use_colnames=True)\n",
    "\n",
    "    if not frequent_itemsets_france.empty:\n",
    "        frequent_itemsets_france = frequent_itemsets_france.sort_values(by='support', ascending=False)\n",
    "        print(f\"\\nEncontrados {len(frequent_itemsets_france)} itemsets frequentes (França) com suporte >= {min_support_france}\")\n",
    "        print(\"\\nTop 5 itemsets frequentes (França):\")\n",
    "        print(frequent_itemsets_france.head(5))\n",
    "\n",
    "        # Gerar Regras de Associação para França\n",
    "        min_confidence_france = 0.2 # Manter a confiança em 0.2 por enquanto\n",
    "        rules_france = association_rules(frequent_itemsets_france, metric=\"confidence\", min_threshold=min_confidence_france)\n",
    "        \n",
    "        if not rules_france.empty:\n",
    "            rules_france = rules_france[rules_france['lift'] > 1]\n",
    "            rules_france = rules_france.sort_values(by=['lift', 'confidence'], ascending=[False, False])\n",
    "            print(f\"\\nEncontradas {len(rules_france)} regras de associação (França) com confiança >= {min_confidence_france} e lift > 1\")\n",
    "            print(\"\\nTop 5 regras de associação (França, ordenadas por lift e confiança):\")\n",
    "            print(rules_france.head(5)[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "        else:\n",
    "            print(\"Nenhuma regra de associação encontrada para a França com os critérios atuais.\")\n",
    "    else:\n",
    "        print(f\"Nenhum itemset frequente encontrado para a França com suporte >= {min_support_france}.\")\n",
    "else:\n",
    "    print(\"Número de transações para a França é muito baixo para uma análise significativa de padrões frequentes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Evaluation (Avaliação Consolidada)\n",
    "\n",
    "Nesta seção, avaliamos os resultados das análises geral e segmentada, conectamos os achados aos objetivos de negócio e discutimos as implicações.\n",
    "\n",
    "### 5.1. Comparação dos Padrões Encontrados\n",
    "\n",
    "*   **Análise Geral (Principalmente UK):**\n",
    "    *   **Itemsets Frequentes Notáveis:** `Cream Hanging Heart T-Light Holder`, `Jumbo Bag Red Retrospot`, `Regency Cakestand 3 Tier`.\n",
    "    *   **Regras Fortes:** Associações muito fortes entre `Herb Markers` (Thyme, Basil, Parsley, Rosemary, Mint) com altíssimo lift e confiança.\n",
    "*   **Análise Segmentada - Alemanha:**\n",
    "    *   **Itemsets Frequentes Notáveis:** `Round Snack Boxes Set Of4 Woodland`, `Round Snack Boxes Set Of 4 Fruits`, `Regency Cakestand 3 Tier`.\n",
    "    *   **Regras Fortes:** Associações fortes entre itens infantis como `(Spaceboy Childrens Cup) <-> (Spaceboy Childrens Bowl)` e `(Childrens Cutlery Spaceboy) <-> (Childrens Cutlery Dolly Girl)`, e também entre designs de canecas.\n",
    "*   **Análise Segmentada - França:**\n",
    "    *   **Itemsets Frequentes Notáveis:** `Rabbit Night Light`, `Red Toadstool Led Night Light`, `Plasters In Tin Circus Parade`.\n",
    "    *   **Regras Fortes:** Associações quase perfeitas (confiança 1.0 ou 0.9) para conjuntos de itens de festa como `(Set/6 Collage Paper Cups) <-> (Set/6 Collage Paper Plates)` e pequenos potes, além de combinações específicas de conjuntos infantis.\n",
    "\n",
    "**Observações da Comparação:**\n",
    "*   Os itens mais populares individualmente e os padrões de associação mais fortes variam consideravelmente entre os segmentos geográficos.\n",
    "*   O `Regency Cakestand 3 Tier` parece ter uma popularidade consistente tanto no UK/Geral quanto na Alemanha.\n",
    "*   A Alemanha e a França mostram fortes padrões de compra de \"conjuntos\" (itens infantis, itens de festa, designs coordenados).\n",
    "*   O Reino Unido (análise geral) se destaca pelo forte cluster dos `Herb Markers`.\n",
    "\n",
    "### 5.2. Visualizações Comparativas (Opcional Avançado)\n",
    "\n",
    "(Poderíamos tentar plotar os top N itens/regras de cada país lado a lado, ou usar grafos comparativos, mas isso pode ser complexo para este escopo. Por ora, a análise descritiva acima é suficiente para a comparação.)\n",
    "\n",
    "### 5.3. Conexão com Objetivos de Negócio e Proposta de Ações (Consolidado)\n",
    "\n",
    "Com base nos padrões gerais e segmentados:\n",
    "\n",
    "*   **Cross-selling/Up-selling e Bundling:**\n",
    "    *   **Geral/UK:** Promover kits de \"Herb Markers\".\n",
    "    *   **Alemanha:** Oferecer conjuntos \"Spaceboy\" (copo+tigela) e \"Childrens Cutlery\" (Spaceboy+Dolly Girl). Promover a compra de múltiplas canecas com designs diferentes.\n",
    "    *   **França:** Criar bundles de itens de festa (\"Kit Festa Collage\"). Oferecer os pares de potes/tigelas identificados. Destacar os conjuntos infantis que são comprados de forma complementar.\n",
    "    *   **Comum:** Para o `Regency Cakestand 3 Tier`, sugerir itens de chá ou confeitaria. Para `Lunch Bags`, sugerir lancheiras ou garrafas.\n",
    "*   **Otimização de Estoque e Promoções:**\n",
    "    *   **Layout:** Agrupar os itens identificados como conjuntos em cada país/região no site ou loja física.\n",
    "    *   **Promoções:**\n",
    "        *   UK: \"Compre 3 marcadores de ervas, leve o 4º com desconto\".\n",
    "        *   Alemanha: \"Leve o conjunto Spaceboy com X% de desconto\".\n",
    "        *   França: \"Desconto na compra do conjunto de pratos e copos de festa\".\n",
    "    *   Considerar o suporte dos itens ao planejar o volume de promoções.\n",
    "\n",
    "### 5.4. Avaliação dos Critérios de Sucesso (Consolidado)\n",
    "\n",
    "*   **Critérios de Mineração:**\n",
    "    *   Dataset completo: 2029 itemsets, 963 regras.\n",
    "    *   Alemanha: 260 itemsets (suporte 0.03), 185 regras (confiança 0.2).\n",
    "    *   França: 1370 itemsets (suporte 0.02), 3737 regras (confiança 0.2).\n",
    "    *   Os parâmetros foram ajustados para os segmentos menores para obter um número razoável de regras, demonstrando flexibilidade na aplicação.\n",
    "*   **Critérios de Negócio:**\n",
    "    *   Foram identificadas regras acionáveis e específicas para diferentes mercados.\n",
    "    *   As visualizações (da Fase 2 e as análises tabulares aqui) ajudam a entender os padrões.\n",
    "    *   Ações práticas foram propostas com base nos achados.\n",
    "\n",
    "### 5.5. Limitações e Próximos Passos\n",
    "\n",
    "*   **Volume de Dados por Segmento:** Para países além de UK, Alemanha e França, o volume de transações é muito baixo para uma análise de regras de associação robusta com os mesmos parâmetros.\n",
    "*   **Análise de \"Tipo de Cliente\":** Não foi realizada devido à falta de dados/critérios para segmentação de clientes no dataset.\n",
    "*   **Outras Métricas:** Focamos em suporte, confiança e lift. Outras métricas poderiam trazer novas perspectivas.\n",
    "*   **Próximos Passos:**\n",
    "    *   Implementar e testar A/B as ações de negócio propostas.\n",
    "    *   Explorar técnicas de clustering de clientes (se dados permitirem) para refinar a segmentação.\n",
    "    *   Analisar a evolução temporal dos padrões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Análise Comparativa: Solução LLM (Fase 2) vs. Solução do Grupo (Fase 3)\n",
    "\n",
    "Nesta seção, comparamos a abordagem e os resultados obtidos com o auxílio direto do LLM na Fase 2 com os desenvolvimentos, refinamentos e análises adicionais realizadas pelo grupo na Fase 3.\n",
    "\n",
    "**Abordagem e Resultados da Fase 2 (Auxílio do LLM):**\n",
    "\n",
    "*   O LLM foi fundamental na estruturação do notebook da Fase 2, seguindo o CRISP-DM.\n",
    "*   Gerou código funcional para carregamento, limpeza básica (nulos, tipos de dados, remoção de quantidades negativas e cancelamentos baseados em 'C' no TransactionNo, embora a remoção de cancelamentos não tenha sido efetiva inicialmente e precisou de ajuste manual no código da Fase 2) e transformação para formato transacional.\n",
    "*   Sugeriu e implementou a modelagem com FP-Growth e a geração de regras de associação com os parâmetros definidos na proposta (`min_support=0.01`, `min_confidence=0.5`).\n",
    "*   Produziu visualizações iniciais (scatter plot e um grafo básico com as top 50 regras por lift).\n",
    "*   As interpretações fornecidas pelo LLM para as regras e gráficos foram genéricas, mas corretas em um nível superficial (ex: identificou o cluster dos Herb Markers).\n",
    "\n",
    "**Desenvolvimentos e Refinamentos da Fase 3 (Grupo):**\n",
    "\n",
    "*   **Consolidação da Limpeza:** O código de limpeza foi revisado e consolidado, garantindo que todas as etapas identificadas como necessárias na Fase 2 fossem aplicadas de forma robusta.\n",
    "*   **Análise Segmentada por País:** Esta foi a principal adição do grupo na Fase 3, atendendo a um objetivo específico da proposta (TP1) que não foi proativamente abordado pelo LLM.\n",
    "    *   Foram realizadas análises separadas para Alemanha e França.\n",
    "    *   Isso exigiu a filtragem dos dados, re-transformação para formato transacional e, crucialmente, o **ajuste dos parâmetros `min_support` e `min_confidence`** para se adequarem ao volume de dados menor de cada segmento. O LLM na Fase 2 aplicou os parâmetros globais. O grupo utilizou uma heurística para ajustar o `min_support` dinamicamente e optou por um `min_confidence` menor para os segmentos.\n",
    "    *   Essa análise segmentada revelou padrões de compra distintos em cada país, que seriam mascarados na análise geral.\n",
    "*   **Aprofundamento da Avaliação:**\n",
    "    *   A interpretação dos resultados foi significativamente aprofundada, comparando os padrões entre os diferentes segmentos e a análise geral.\n",
    "    *   Foram propostas ações de negócio mais específicas e direcionadas para cada segmento, além das gerais.\n",
    "    *   A avaliação dos critérios de sucesso foi feita de forma mais explícita e consolidada.\n",
    "*   **Refinamento da Interpretação do Grafo:** A interpretação do grafo de rede foi elaborada com mais detalhes, identificando múltiplos clusters e suas implicações de negócio.\n",
    "*   **Identificação de Limitações:** O grupo identificou limitações mais específicas da análise, como a questão do volume de dados para outros segmentos e a ausência de análise por tipo de cliente.\n",
    "\n",
    "**Justificativas para as Mudanças/Adições:**\n",
    "\n",
    "*   A **análise segmentada** foi realizada para cumprir um requisito explícito da Proposta TP1 e para obter insights mais granulares e acionáveis, reconhecendo que o comportamento do consumidor pode variar geograficamente.\n",
    "*   O **ajuste de parâmetros** para os segmentos foi necessário porque aplicar os mesmos limiares do dataset completo a subconjuntos muito menores resultaria em poucas ou nenhuma regra significativa.\n",
    "*   O **aprofundamento da avaliação e das propostas de ação** reflete a análise crítica humana, que vai além da geração de resultados e busca extrair valor de negócio e reconhecer as nuances dos dados.\n",
    "\n",
    "**Aprendizados sobre o Uso do LLM:**\n",
    "\n",
    "*   **Eficiência na Prototipagem:** O LLM é excelente para gerar rapidamente o esqueleto do projeto e o código para tarefas padrão, economizando tempo na fase inicial de desenvolvimento.\n",
    "*   **Necessidade de Direcionamento Específico:** Para objetivos mais específicos ou análises mais detalhadas (como a segmentação ou o ajuste fino de parâmetros para subconjuntos), o LLM requer prompts muito precisos ou a intervenção humana para identificar e implementar essas etapas.\n",
    "*   **Interpretação vs. Geração:** O LLM pode gerar interpretações básicas, mas a análise crítica, a conexão com o contexto de negócio específico e a identificação de insights mais profundos ainda são predominantemente tarefas humanas.\n",
    "*   **Limitações Técnicas (Interação):** A dificuldade do LLM em editar diretamente o notebook foi um ponto de atrito, embora contornável.\n",
    "\n",
    "**Conclusão da Análise Comparativa:**\n",
    "\n",
    "A Fase 2, com auxílio do LLM, forneceu uma base sólida e acelerou o desenvolvimento inicial. A Fase 3, conduzida pelo grupo, construiu sobre essa base, adicionando análises mais complexas e específicas (segmentação), refinando a interpretação e a avaliação, e demonstrando a importância da análise crítica humana para extrair valor máximo dos resultados da mineração de dados. O LLM foi um bom \"primeiro analista\" ou \"assistente de codificação\", mas a profundidade e a especificidade da análise final foram contribuições do grupo.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Considerações Finais da Fase 3 e do Projeto\n",
    "\n",
    "Este trabalho prático permitiu aplicar o processo de Mineração de Dados, desde a compreensão do negócio até a avaliação dos resultados, em um dataset real de e-commerce. O foco na mineração de padrões frequentes revelou associações interessantes entre produtos, tanto na análise geral quanto nas análises segmentadas por país (Alemanha e França).\n",
    "\n",
    "**Principais Conquistas:**\n",
    "\n",
    "*   Implementação bem-sucedida do fluxo CRISP-DM.\n",
    "*   Limpeza e preparação eficazes dos dados.\n",
    "*   Aplicação do algoritmo FP-Growth e geração de regras de associação significativas.\n",
    "*   Identificação de padrões de compra distintos para o mercado geral (UK) e para segmentos específicos (Alemanha, França), levando a propostas de ações de negócio direcionadas.\n",
    "*   Utilização e avaliação crítica de um LLM como ferramenta auxiliar no processo.\n",
    "\n",
    "**Desafios e Aprendizados:**\n",
    "\n",
    "*   A necessidade de ajustar os parâmetros de mineração (`min_support`, `min_confidence`) para diferentes volumes de dados (dataset completo vs. segmentos) foi um aprendizado importante.\n",
    "*   A interpretação das regras e a tradução dos padrões em ações de negócio acionáveis requerem um bom entendimento do contexto e análise crítica.\n",
    "*   A análise segmentada, embora mais trabalhosa, pode fornecer insights muito mais valiosos do que uma análise puramente agregada, especialmente em datasets com diversidade geográfica ou de clientes.\n",
    "\n",
    "**Trabalhos Futuros (Além do Escopo deste TP):**\n",
    "\n",
    "*   Explorar outros países com volume de dados suficiente.\n",
    "*   Incorporar a dimensão temporal para identificar sazonalidades ou tendências nos padrões de compra.\n",
    "*   Utilizar métricas adicionais para avaliação de regras.\n",
    "*   Se dados permitirem, segmentar a análise por tipo de cliente.\n",
    "*   Testar a implementação das ações de negócio propostas e medir seu impacto.\n",
    "\n",
    "Este projeto cumpriu os objetivos definidos na proposta, fornecendo uma base sólida de insights sobre o comportamento de compra dos clientes e demonstrando o valor da mineração de regras de associação para o e-commerce."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
