<!-- Generated by SpecStory -->

# Fase 2 do Trabalho de Mineração de Dados (2025-05-02 18:43:54)

_**User**_

Iremos fazer um trabalho prático de mineiração de dados. Se contextualize com a proposta atraves dos documentos

---

_**Assistant**_



---

Ok, entendi. Analisei os documentos fornecidos para me contextualizar sobre o trabalho prático de mineração de dados.

**Resumo do Contexto:**

1.  **Projeto Geral:** O trabalho prático envolve a aplicação de técnicas de mineração de dados seguindo a metodologia CRISP-DM. Ele é dividido em três fases:
    *   **Fase 1 (Proposta):** Definição do problema, dataset, relevância e plano inicial.
    *   **Fase 2 (Uso de LLM):** Utilização de um Modelo de Linguagem Grande (LLM) para auxiliar na execução da tarefa, registrando e criticando a interação.
    *   **Fase 3 (Trabalho Completo):** Execução completa da tarefa, integrando aprendizados das fases anteriores, corrigindo possíveis erros da LLM e entregando a solução final (Jupyter Notebook) com uma análise comparativa.

2.  **Proposta Específica (TP1 - Gilmar e Fabrício):**
    *   **Arquivo:** `fase1/TP1_Proposta_gilmar_e_fabricio.md`
    *   **Tema:** Mineração de Padrões Frequentes em Dados de E-commerce do Reino Unido.
    *   **Objetivo Principal:** Identificar itens frequentemente comprados juntos para otimizar estratégias de marketing (*cross-selling*, *up-selling*), estoque e promoções.
    *   **Dataset:** Dados de transações de um e-commerce (aprox. 500 mil linhas).
    *   **Metodologia:**
        *   Pré-processamento para limpar transações canceladas e agrupar itens por transação.
        *   Aplicação dos algoritmos Apriori e/ou FP-Growth para encontrar *itemsets* frequentes (`min_support=0.01`).
        *   Geração de regras de associação (`min_confidence=0.5`).
        *   Análise e visualização das regras (filtrando por `lift > 1`).
    *   **Ferramentas:** Python (com bibliotecas relevantes).

3.  **Documentação de Apoio:**
    *   `docs/Documentacao_Tp_MD.md`: Descreve as fases do trabalho, restrições do dataset (mínimo 1000 linhas, 4 colunas), a estrutura esperada do Jupyter Notebook (seguindo o CRISP-DM: Business Understanding, Data Understanding & Preparation, Modeling, Evaluation) e os algoritmos específicos para mineração de padrões frequentes (Apriori, Eclat, FP-Growth, Association Rules).
    *   `docs/guia-usr-pt-crispdm-v201902.md`: É um guia detalhado sobre a metodologia CRISP-DM, explicando cada uma das 6 fases (Entendimento do Negócio, Entendimento dos Dados, Preparação de Dados, Modelagem, Avaliação, Implantação) e suas respectivas tarefas e saídas.
    *   `README.md`: Descreve a estrutura do repositório e o conteúdo esperado na proposta da Fase 1.

Em suma, o trabalho consiste em aplicar algoritmos como Apriori e FP-Growth em um dataset de e-commerce para encontrar regras de associação, seguindo as fases e a estrutura definidas no documento geral do TP e na metodologia CRISP-DM. A Fase 2 introduz o uso de LLMs como ferramenta auxiliar, e a Fase 3 consolida o trabalho completo.

Estou pronto para prosseguir com as próximas etapas ou responder a perguntas específicas sobre o projeto.

---

